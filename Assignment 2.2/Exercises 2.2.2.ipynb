{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0decde1",
   "metadata": {},
   "source": [
    "### Use mlflow to track the parameters for your housing library code. You already have scripts for data preparation, model training, model scoring. Use mlflow to track the parameters and any useful metrics in these scripts. Also, create a main script that runs everything together under a single parent mlflow run-id. Each of the child tasks (i.e. data preparation, model training etc) should get their own mlflow run-id but run as child runs of the main run. See the documentation of the start_run function to see how to create nested runs. Create a PR with your changes and submit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b176c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline   \n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15652693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow server --backend-store-uri mlruns/ --default-artifact-root mlruns/ --host 0.0.0.0 --port 5000\n",
    "remote_server_uri = \"http://127.0.0.1:5000\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)  # or set the MLFLOW_TRACKING_URI in the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9dcb713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/05 12:55:09 INFO mlflow.tracking.fluent: Experiment with name 'House_price_prediction' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/2', creation_time=1680679509641, experiment_id='2', last_update_time=1680679509641, lifecycle_stage='active', name='House_price_prediction', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"House_price_prediction\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c028c65",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00416f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1f14151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af7e8466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas dataframe\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1fd5fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [118185.0373804   69988.32636693  82703.45099603  74262.4992966\n",
      "  89608.19120531  81062.90690825  66958.32707689 101452.44849817\n",
      "  93194.25525259  72014.8909069 ]\n",
      "Mean: 84943.03338880667\n",
      "Standard deviation: 15217.794475188668\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"Hosuse_price_prediction\"):\n",
    "    \n",
    "    housing=load_housing_data()\n",
    "    mlflow.log_param(\"read_data\", 1)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"data_prepare\",nested=True):\n",
    "        housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "        housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "        housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "        housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]\n",
    "        housing1=housing\n",
    "        housing = housing1.drop(\"median_house_value\", axis=1)\n",
    "        housing_labels = housing1[\"median_house_value\"].copy()\n",
    "        housing.drop(\"income_cat\", axis=1,inplace=True)\n",
    "        mlflow.log_param(\"data_shape\", housing.shape)\n",
    "        \n",
    "        \n",
    "    with mlflow.start_run(run_name=\"data_cleaning\",nested=True):   \n",
    "        median = housing[\"total_bedrooms\"].median()  # option 3\n",
    "        housing[\"total_bedrooms\"].fillna(median, inplace=True)\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        imputer = SimpleImputer(strategy=\"median\")\n",
    "        housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "        imputer.fit(housing_num)\n",
    "        imputer.statistics_\n",
    "        X = imputer.transform(housing_num)\n",
    "        housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
    "                          index=housing_num.index)\n",
    "        housing_cat = housing[[\"ocean_proximity\"]]\n",
    "        ## OrdinalEncoder\n",
    "        from sklearn.preprocessing import OrdinalEncoder\n",
    "        ordinal_encoder = OrdinalEncoder()\n",
    "        housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        cat_encoder = OneHotEncoder()\n",
    "        housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "        housing_cat_1hot\n",
    "        housing_cat_1hot.shape\n",
    "        \n",
    "        from sklearn.pipeline import Pipeline\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "        num_pipeline = Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                ('std_scaler', StandardScaler()),\n",
    "            ])\n",
    "\n",
    "        housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "        \n",
    "        from sklearn.compose import ColumnTransformer\n",
    "\n",
    "        num_attribs = list(housing_num)\n",
    "        cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "        full_pipeline = ColumnTransformer([\n",
    "                (\"num\", num_pipeline, num_attribs),\n",
    "                (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "            ])\n",
    "\n",
    "        housing_prepared = full_pipeline.fit_transform(housing)\n",
    "        mlflow.log_param(\"data_shape\", housing_prepared.shape)\n",
    "        \n",
    "    with mlflow.start_run(run_name=\"model_training\",nested=True):\n",
    "        \n",
    "        # linear Regression\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        lin_reg = LinearRegression()\n",
    "        lin_reg.fit(housing_prepared, housing_labels)\n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        tree_reg = DecisionTreeRegressor()\n",
    "        tree_reg.fit(housing_prepared, housing_labels)\n",
    "        housing_predictions = tree_reg.predict(housing_prepared)\n",
    "        cv=10\n",
    "        mlflow.log_param(\"number_of_fold\", cv)\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
    "                                 scoring=\"neg_mean_squared_error\", cv=10)\n",
    "        tree_rmse_scores = np.sqrt(-scores)\n",
    "        def display_scores(scores):\n",
    "            print(\"Scores:\", scores)\n",
    "            print(\"Mean:\", scores.mean())\n",
    "            print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "        display_scores(tree_rmse_scores)\n",
    "\n",
    "        lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
    "                                    scoring=\"neg_mean_squared_error\", cv=10)\n",
    "        lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "        mlflow.log_metric(\"mean_of_mean_squar_error\", lin_rmse_scores.mean())\n",
    "        mlflow.log_metric(\"std_of_mean_squar_error\", lin_rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc7097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
